{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a44e1e-20d7-4ed2-a726-674546d2869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Milestone 4 ‚Äî Advanced model (safe + faster tuning for small data)\n",
    "- Uses LightGBM (if available) + RandomForest baseline\n",
    "- Hyperparameter tuning with RandomizedSearchCV (reduced scope)\n",
    "- TimeSeriesSplit for CV (smaller splits)\n",
    "- Saves models, plots, and evaluation CSV\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_PATH = \"traffic.csv\"\n",
    "OUT_DIR = \"milestone4_outputs_advanced\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"models\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"plots\"), exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "USE_LIGHTGBM = True      \n",
    "SKIP_TUNING = False      \n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è LightGBM not available ‚Äî will use RandomForest only.\")\n",
    "    USE_LIGHTGBM = False\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** 0.5\n",
    "\n",
    "def safe_load_csv(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path} ‚Äî ÿ∂ÿπ ŸÖŸÑŸÅ traffic_data.csv ŸÅŸä ŸÜŸÅÿ≥ ÿßŸÑŸÖÿ¨ŸÑÿØ ÿ£Ÿà ÿπÿØŸëŸÑ DATA_PATH\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "df = safe_load_csv(DATA_PATH)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(['street_name', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} rows ‚Äî columns: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['weekday'] = df['timestamp'].dt.weekday\n",
    "df['is_weekend'] = df['weekday'].isin([5,6]).astype(int)\n",
    "\n",
    "\n",
    "LAGS = [1,2,3]\n",
    "for lag in LAGS:\n",
    "    df[f'veh_count_lag_{lag}'] = df.groupby('street_name')['vehicle_count'].shift(lag)\n",
    "df['veh_roll_3'] = df.groupby('street_name')['vehicle_count'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "df['vehicle_count_next'] = df.groupby('street_name')['vehicle_count'].shift(-1)\n",
    "le_light = LabelEncoder()\n",
    "df['lighting_demand_enc'] = le_light.fit_transform(df['lighting_demand'])\n",
    "\n",
    "\n",
    "cat_cols = ['street_name','light_level','weather','traffic_light']\n",
    "label_encoders = {}\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[c + '_enc'] = le.fit_transform(df[c])\n",
    "    label_encoders[c] = le\n",
    "\n",
    "\n",
    "required = ['vehicle_count_next'] + [f'veh_count_lag_{max(LAGS)}']\n",
    "df_model = df.dropna(subset=required).copy()\n",
    "print(f\"Rows available for modeling after dropna: {len(df_model)}\")\n",
    "\n",
    "\n",
    "FEATURES = [\n",
    "    'vehicle_count','vehicle_speed','solar_energy_level',\n",
    "    'hour','weekday','is_weekend','veh_roll_3'\n",
    "] + [f'veh_count_lag_{l}' for l in LAGS] + [c + '_enc' for c in cat_cols]\n",
    "\n",
    "X = df_model[FEATURES]\n",
    "y_reg = df_model['vehicle_count_next']\n",
    "y_clf = df_model['lighting_demand_enc']\n",
    "\n",
    "\n",
    "unique_times = df_model['timestamp'].sort_values().unique()\n",
    "split_idx = int(len(unique_times) * 0.8) if len(unique_times) > 1 else 0\n",
    "time_cutoff = unique_times[split_idx]\n",
    "train_mask = df_model['timestamp'] <= time_cutoff\n",
    "\n",
    "X_train, X_test = X[train_mask], X[~train_mask]\n",
    "y_train_reg, y_test_reg = y_reg[train_mask], y_reg[~train_mask]\n",
    "y_train_clf, y_test_clf = y_clf[train_mask], y_clf[~train_mask]\n",
    "\n",
    "print(f\"Train rows: {len(X_train)}, Test rows: {len(X_test)}\")\n",
    "\n",
    "y_pred_baseline = X_test[f\"veh_count_lag_{LAGS[0]}\"]\n",
    "baseline_mae = mean_absolute_error(y_test_reg, y_pred_baseline)\n",
    "print(f\"Baseline persistence MAE: {baseline_mae:.3f}\")\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "rf_reg.fit(X_train, y_train_reg)\n",
    "y_pred_rf_reg = rf_reg.predict(X_test)\n",
    "rf_reg_mae = mean_absolute_error(y_test_reg, y_pred_rf_reg)\n",
    "rf_reg_rmse = rmse(y_test_reg, y_pred_rf_reg)\n",
    "print(f\"RF Regressor ‚Äî MAE: {rf_reg_mae:.3f}, RMSE: {rf_reg_rmse:.3f}\")\n",
    "\n",
    "rf_clf.fit(X_train, y_train_clf)\n",
    "y_pred_rf_clf = rf_clf.predict(X_test)\n",
    "rf_clf_acc = accuracy_score(y_test_clf, y_pred_rf_clf) if len(y_test_clf)>0 else None\n",
    "print(f\"RF Classifier ‚Äî Accuracy: {rf_clf_acc}\")\n",
    "\n",
    "\n",
    "best_reg = rf_reg\n",
    "best_clf = rf_clf\n",
    "results_summary = {}\n",
    "\n",
    "\n",
    "n_splits_cv = min(3, max(2, int(len(X_train) / 10)))  \n",
    "tscv = TimeSeriesSplit(n_splits=n_splits_cv)\n",
    "\n",
    "if USE_LIGHTGBM and not SKIP_TUNING:\n",
    "    print(\"üî∑ Running LightGBM + RandomizedSearchCV (regressor + classifier) ‚Äî reduced scope for speed...\")\n",
    "    \n",
    "    reg_param_dist = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'num_leaves': [15, 31, 63],\n",
    "        'min_child_samples': [5, 10, 20],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "    }\n",
    "    lgb_reg = LGBMRegressor(random_state=RANDOM_STATE, n_jobs=1)  \n",
    "\n",
    "    reg_search = RandomizedSearchCV(\n",
    "        estimator=lgb_reg,\n",
    "        param_distributions=reg_param_dist,\n",
    "        n_iter=5,              \n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1,            \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        reg_search.fit(X_train, y_train_reg)\n",
    "        best_reg = reg_search.best_estimator_\n",
    "        print(\"Best regressor params:\", reg_search.best_params_)\n",
    "        y_pred_lgb_reg = best_reg.predict(X_test)\n",
    "        lgb_reg_mae = mean_absolute_error(y_test_reg, y_pred_lgb_reg)\n",
    "        lgb_reg_rmse = rmse(y_test_reg, y_pred_lgb_reg)\n",
    "        print(f\"LGB Regressor ‚Äî MAE: {lgb_reg_mae:.3f}, RMSE: {lgb_reg_rmse:.3f}\")\n",
    "        results_summary['lgb_reg'] = {'mae': lgb_reg_mae, 'rmse': lgb_reg_rmse}\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"‚ö†Ô∏è Tuning interrupted by user ‚Äî falling back to RandomForest regressor.\")\n",
    "        best_reg = rf_reg\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Reg search failed, fallback to RandomForest regressor. Error:\", e)\n",
    "        best_reg = rf_reg\n",
    "\n",
    "    # Classifier param grid (smaller)\n",
    "    clf_param_dist = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.05],\n",
    "        'num_leaves': [15, 31],\n",
    "        'min_child_samples': [5, 10],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "    }\n",
    "    lgb_clf = LGBMClassifier(random_state=RANDOM_STATE, n_jobs=1)\n",
    "    clf_search = RandomizedSearchCV(\n",
    "        estimator=lgb_clf,\n",
    "        param_distributions=clf_param_dist,\n",
    "        n_iter=5,\n",
    "        cv=tscv,\n",
    "        scoring='accuracy',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        clf_search.fit(X_train, y_train_clf)\n",
    "        best_clf = clf_search.best_estimator_\n",
    "        print(\"Best classifier params:\", clf_search.best_params_)\n",
    "        y_pred_lgb_clf = best_clf.predict(X_test)\n",
    "        lgb_clf_acc = accuracy_score(y_test_clf, y_pred_lgb_clf) if len(y_test_clf)>0 else None\n",
    "        print(f\"LGB Classifier ‚Äî Accuracy: {lgb_clf_acc}\")\n",
    "        results_summary['lgb_clf'] = {'acc': lgb_clf_acc}\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"‚ö†Ô∏è Tuning interrupted by user ‚Äî falling back to RandomForest classifier.\")\n",
    "        best_clf = rf_clf\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Clf search failed, fallback to RandomForest classifier. Error:\", e)\n",
    "        best_clf = rf_clf\n",
    "\n",
    "else:\n",
    "    if not USE_LIGHTGBM:\n",
    "        print(\"Skipping LightGBM tuning (not installed).\")\n",
    "    elif SKIP_TUNING:\n",
    "        print(\"SKIP_TUNING is True ‚Äî skipping LightGBM RandomizedSearchCV (using default LightGBM or RandomForest).\")\n",
    "       \n",
    "        if USE_LIGHTGBM:\n",
    "            try:\n",
    "                quick_reg = LGBMRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=1)\n",
    "                quick_clf = LGBMClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=1)\n",
    "                quick_reg.fit(X_train, y_train_reg)\n",
    "                best_reg = quick_reg\n",
    "                quick_clf.fit(X_train, y_train_clf)\n",
    "                best_clf = quick_clf\n",
    "            except Exception:\n",
    "                best_reg = rf_reg\n",
    "                best_clf = rf_clf\n",
    "\n",
    "\n",
    "\n",
    "if 'lgb_reg' in results_summary and results_summary['lgb_reg']['mae'] < rf_reg_mae:\n",
    "    chosen_reg = best_reg\n",
    "    chosen_reg_name = \"LightGBM Regressor\"\n",
    "    chosen_reg_scores = results_summary['lgb_reg']\n",
    "else:\n",
    "    chosen_reg = rf_reg\n",
    "    chosen_reg_name = \"RandomForest Regressor\"\n",
    "    chosen_reg_scores = {'mae': rf_reg_mae, 'rmse': rf_reg_rmse}\n",
    "\n",
    "\n",
    "if 'lgb_clf' in results_summary and results_summary['lgb_clf']['acc'] is not None and results_summary['lgb_clf']['acc'] >= rf_clf_acc:\n",
    "    chosen_clf = best_clf\n",
    "    chosen_clf_name = \"LightGBM Classifier\"\n",
    "else:\n",
    "    chosen_clf = rf_clf\n",
    "    chosen_clf_name = \"RandomForest Classifier\"\n",
    "\n",
    "\n",
    "y_pred_chosen_reg = chosen_reg.predict(X_test)\n",
    "y_pred_chosen_clf = chosen_clf.predict(X_test)\n",
    "\n",
    "print(f\"üîî Final chosen regressor: {chosen_reg_name}\")\n",
    "print(f\"Final regressor MAE: {mean_absolute_error(y_test_reg, y_pred_chosen_reg):.3f}, RMSE: {rmse(y_test_reg, y_pred_chosen_reg):.3f}\")\n",
    "print(f\"üîî Final chosen classifier: {chosen_clf_name}\")\n",
    "print(\"Classification report (chosen classifier):\")\n",
    "\n",
    "print(classification_report(y_test_clf, y_pred_chosen_clf, \n",
    "                            labels=np.arange(len(le_light.classes_)), \n",
    "                            target_names=le_light.classes_))\n",
    "\n",
    "perm_reg = permutation_importance(chosen_reg, X_test, y_test_reg, n_repeats=20, random_state=RANDOM_STATE, n_jobs=1)\n",
    "perm_clf = permutation_importance(chosen_clf, X_test, y_test_clf, n_repeats=20, random_state=RANDOM_STATE, n_jobs=1)\n",
    "\n",
    "imp_reg = pd.Series(perm_reg.importances_mean, index=FEATURES).sort_values(ascending=False)\n",
    "imp_clf = pd.Series(perm_clf.importances_mean, index=FEATURES).sort_values(ascending=False)\n",
    "\n",
    "if imp_clf.sum() == 0:\n",
    "    print(\"‚ö†Ô∏è Classifier permutation importances all zero ‚Äî using built-in feature_importances_.\")\n",
    "    try:\n",
    "        imp_clf = pd.Series(chosen_clf.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "imp_reg.head(12).sort_values().plot.barh()\n",
    "plt.title(\"Top Features ‚Äî Regressor (permutation)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"plots\", \"feature_importance_reg.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "imp_clf.head(12).sort_values().plot.barh()\n",
    "plt.title(\"Top Features ‚Äî Classifier (permutation or builtin)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"plots\", \"feature_importance_clf.png\"))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "joblib.dump(chosen_reg, os.path.join(OUT_DIR, \"models\", \"chosen_regressor.pkl\"))\n",
    "joblib.dump(chosen_clf, os.path.join(OUT_DIR, \"models\", \"chosen_classifier.pkl\"))\n",
    "joblib.dump(le_light, os.path.join(OUT_DIR, \"models\", \"label_encoder_lighting.pkl\"))\n",
    "for k,v in label_encoders.items():\n",
    "    joblib.dump(v, os.path.join(OUT_DIR, \"models\", f\"label_encoder_{k}.pkl\"))\n",
    "-\n",
    "eval_df = X_test.copy()\n",
    "eval_df['true_vehicle_next'] = y_test_reg.values\n",
    "eval_df['pred_vehicle_next'] = y_pred_chosen_reg\n",
    "eval_df['true_lighting'] = le_light.inverse_transform(y_test_clf.values)\n",
    "eval_df['pred_lighting'] = le_light.inverse_transform(y_pred_chosen_clf)\n",
    "eval_df.to_csv(os.path.join(OUT_DIR, \"evaluation_predictions.csv\"), index=False)\n",
    "\n",
    "print(\"‚úÖ All outputs saved to:\", OUT_DIR)\n",
    "print(\"- Models:\", os.listdir(os.path.join(OUT_DIR, \"models\")))\n",
    "print(\"- Plots:\", os.listdir(os.path.join(OUT_DIR, \"plots\")))\n",
    "print(\"- Eval file:\", os.path.join(OUT_DIR, \"evaluation_predictions.csv\"))\n",
    "\n",
    "\n",
    "def predict_new_simple(input_dict):\n",
    "    df_in = pd.DataFrame([input_dict])\n",
    "    X_in = df_in[FEATURES]\n",
    "    pc = chosen_reg.predict(X_in)[0]\n",
    "   \n",
    "    pl_int = int(chosen_clf.predict(X_in)[0]) \n",
    "    pl = le_light.inverse_transform([pl_int])[0]\n",
    "    return {'pred_vehicle_next': float(pc), 'pred_lighting': pl}\n",
    "\n",
    "\n",
    "if len(X_test) > 0:\n",
    "    example = X_test.iloc[-1].to_dict()\n",
    "    print(\"\\nExample prediction (last test row):\", predict_new_simple(example))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03775f0-0b57-427c-801e-8b40b101f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# milestone4_streaming_predictor_v1.py\n",
    "\"\"\"\n",
    "Milestone 4 ‚Äî Real-Time Streaming Predictor (Original Strong Model)\n",
    "Reads live data from Kafka topic 'traffic-stream',\n",
    "predicts vehicle count next & lighting demand,\n",
    "and sends predictions to 'traffic-predictions' topic.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os \n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "KAFKA_BROKER = \"kafka:9092\"\n",
    "INPUT_TOPIC = \"traffic_topic\"\n",
    "OUTPUT_TOPIC = \"traffic-predictions\"\n",
    "\n",
    "MODEL_DIR = \"milestone4_outputs_advanced/models\"\n",
    "\n",
    "\n",
    "REGRESSOR_PATH = os.path.join(MODEL_DIR, \"chosen_regressor.pkl\")\n",
    "CLASSIFIER_PATH = os.path.join(MODEL_DIR, \"chosen_classifier.pkl\")\n",
    "ENCODER_LIGHT_PATH = os.path.join(MODEL_DIR, \"label_encoder_lighting.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"üì¶ Loading trained models...\")\n",
    "try:\n",
    "    regressor = joblib.load(REGRESSOR_PATH)\n",
    "    classifier = joblib.load(CLASSIFIER_PATH)\n",
    "    le_light = joblib.load(ENCODER_LIGHT_PATH)\n",
    "    print(\"‚úÖ Models loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå FileNotFoundError: Failed to load models. Check the path: {e}\")\n",
    "    exit() \n",
    "\n",
    "\n",
    "print(f\"üîå Connecting to Kafka broker at {KAFKA_BROKER}...\")\n",
    "consumer = KafkaConsumer(\n",
    "    INPUT_TOPIC,\n",
    "    bootstrap_servers=KAFKA_BROKER,\n",
    "    value_deserializer=lambda x: json.loads(x.decode(\"utf-8\")),\n",
    ")\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=KAFKA_BROKER,\n",
    "    value_serializer=lambda x: json.dumps(x).encode(\"utf-8\"),\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Connected to Kafka ‚Äî Listening for messages on topic '{INPUT_TOPIC}'...\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "\n",
    "FEATURES = [\n",
    "    'vehicle_count','vehicle_speed','solar_energy_level',\n",
    "    'hour','weekday','is_weekend','veh_roll_3',\n",
    "    'veh_count_lag_1','veh_count_lag_2','veh_count_lag_3',\n",
    "    'street_name_enc','light_level_enc','weather_enc','traffic_light_enc'\n",
    "]\n",
    "\n",
    "\n",
    "def prepare_input(data):\n",
    "   \n",
    "    for f in FEATURES:\n",
    "       \n",
    "        if f not in data or data[f] is None:\n",
    "            data[f] = 0 \n",
    "\n",
    "\n",
    "    X_new = pd.DataFrame([data], columns=FEATURES)\n",
    "    return X_new\n",
    "\n",
    "for msg in consumer:\n",
    "    try:\n",
    "        data = msg.value\n",
    "        print(f\"\\nüì• New data received: {data}\")\n",
    "\n",
    "   \n",
    "        data[\"timestamp\"] = data.get(\"timestamp\", datetime.now().isoformat())\n",
    "\n",
    "      \n",
    "        X_new = prepare_input(data)\n",
    "\n",
    "     \n",
    "        pred_vehicle_next = float(regressor.predict(X_new)[0])\n",
    "        \n",
    "        pred_lighting_encoded = classifier.predict(X_new)\n",
    "        pred_lighting = le_light.inverse_transform(pred_lighting_encoded.astype(int))[0]\n",
    "\n",
    "       \n",
    "        result = {\n",
    "            \"timestamp\": data[\"timestamp\"],\n",
    "            \"street_name\": data.get(\"street_name\", \"unknown\"),\n",
    "            \"predicted_vehicle_count_next\": round(pred_vehicle_next, 2),\n",
    "            \"predicted_lighting_demand\": pred_lighting\n",
    "        }\n",
    "\n",
    "        \n",
    "        producer.send(OUTPUT_TOPIC, value=result)\n",
    "        producer.flush()  \n",
    "\n",
    "        print(f\"üì° Sent prediction ‚Üí Topic '{OUTPUT_TOPIC}': {result}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing message: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
