{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc14be70-9edb-41a9-90f3-4ec2c8e6e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b180dced-59d8-4f79-911e-ca6eca7122b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0eeff1b-a292-4e12-9c0d-f9ed67a73b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark with Kafka is ready!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaTest\") \\\n",
    "    .config(\n",
    "        \"spark.jars\",\n",
    "        \"/opt/spark/jars/spark-sql-kafka-0-10_2.13-4.0.1.jar,\"\n",
    "        \"/opt/spark/jars/kafka-clients-3.7.0.jar,\"\n",
    "        \"/opt/spark/jars/spark-token-provider-kafka-0-10_2.13-4.0.1.jar,\"\n",
    "        \"/opt/spark/jars/mssql-jdbc-13.2.1.jre11.jar\"\n",
    "    ) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark with Kafka is ready!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da08eb8-38ba-4817-8aa2-162cea494a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "\n",
    "JAR_PATH = \"/opt/spark/jars/mssql-jdbc-13.2.1.jre11.jar\" \n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TrafficKafkaStreaming\") \\\n",
    "    .config(\"spark.jars\", JAR_PATH) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31d8740-9f33-43c2-9cf0-085701c73f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TrafficKafkaStreaming\").getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"traffic_topic\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "\n",
    "json_df = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", StringType()),\n",
    "    StructField(\"street_name\", StringType()),\n",
    "    StructField(\"vehicle_count\", IntegerType()),\n",
    "    StructField(\"vehicle_speed\", DoubleType()),\n",
    "    StructField(\"light_level\", StringType()),\n",
    "    StructField(\"weather\", StringType()),\n",
    "    StructField(\"traffic_light\", StringType()),\n",
    "    StructField(\"solar_energy_level\", DoubleType()),\n",
    "    StructField(\"lighting_demand\", StringType())\n",
    "])\n",
    "\n",
    "\n",
    "parsed_df = json_df.select(from_json(col(\"value\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "\n",
    "df_transformed = (parsed_df\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\")))\n",
    "    .withColumn(\"hour_of_day\", hour(col(\"timestamp\")))\n",
    "    .withColumn(\"day_of_week\", date_format(col(\"timestamp\"), \"EEEE\"))\n",
    "    .withColumn(\"Is_peak_hour\", when((col(\"hour_of_day\").between(7, 9)) | (col(\"hour_of_day\").between(16, 18)), 1).otherwise(0))\n",
    "    .withColumn(\"congestion_level\", when((col(\"vehicle_count\") >= 30) & (col(\"vehicle_speed\") <= 20), \"High\")\n",
    "                                    .when((col(\"vehicle_count\") >= 15) & (col(\"vehicle_speed\") <= 40), \"Medium\")\n",
    "                                    .otherwise(\"Low\"))\n",
    "    .withColumn(\"Is_congested\", when(col(\"congestion_level\") == \"High\", 1).otherwise(0))\n",
    "    .withColumn(\"lighting_demand_kW\", when(col(\"lighting_demand\") == \"low\", 0.5)\n",
    "                                      .when(col(\"lighting_demand\") == \"medium\", 2.0)\n",
    "                                      .when(col(\"lighting_demand\") == \"high\", 5.0))\n",
    "    .withColumn(\"lighting_consumption_kWh\", \n",
    "                when(col(\"lighting_demand_kW\") - col(\"solar_energy_level\") > 0,\n",
    "                     col(\"lighting_demand_kW\") - col(\"solar_energy_level\"))\n",
    "                .otherwise(0.0))\n",
    "    .withColumn(\"energy_alert_flag\", (col(\"lighting_consumption_kWh\") > 2.0))\n",
    ")\n",
    "\n",
    "\n",
    "query = df_transformed.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", \"/home/jovyan/work/data_lake/processed_data\") \\\n",
    "    .option(\"checkpointLocation\", \"/home/jovyan/work/data_lake/checkpoints\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b0315-1794-46fa-ba06-59b2bedfdce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********************************************************Don not touch #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc79835-8a99-4fee-ac45-c8cb750f6cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Writing batch 187 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1503 rows to traffic_sensors_data.\n",
      "  -> Wrote 1503 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1503 rows to traffic_energy_analysis.\n",
      "Batch 187 successfully processed and written to 3 tables.\n",
      "--- Writing batch 188 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 5 rows to traffic_sensors_data.\n",
      "  -> Wrote 5 rows to traffic_weather_conditions.\n",
      "  -> Wrote 5 rows to traffic_energy_analysis.\n",
      "Batch 188 successfully processed and written to 3 tables.\n",
      "--- Writing batch 189 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 189 successfully processed and written to 3 tables.\n",
      "--- Writing batch 190 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 190 successfully processed and written to 3 tables.\n",
      "--- Writing batch 191 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 191 successfully processed and written to 3 tables.\n",
      "--- Writing batch 192 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 192 successfully processed and written to 3 tables.\n",
      "--- Writing batch 193 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 193 successfully processed and written to 3 tables.\n",
      "--- Writing batch 194 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 194 successfully processed and written to 3 tables.\n",
      "--- Writing batch 195 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 195 successfully processed and written to 3 tables.\n",
      "--- Writing batch 196 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 196 successfully processed and written to 3 tables.\n",
      "--- Writing batch 197 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 197 successfully processed and written to 3 tables.\n",
      "--- Writing batch 198 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 198 successfully processed and written to 3 tables.\n",
      "--- Writing batch 199 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 199 successfully processed and written to 3 tables.\n",
      "--- Writing batch 200 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 200 successfully processed and written to 3 tables.\n",
      "--- Writing batch 201 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 201 successfully processed and written to 3 tables.\n",
      "--- Writing batch 202 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 202 successfully processed and written to 3 tables.\n",
      "--- Writing batch 203 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 203 successfully processed and written to 3 tables.\n",
      "--- Writing batch 204 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 204 successfully processed and written to 3 tables.\n",
      "--- Writing batch 205 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 205 successfully processed and written to 3 tables.\n",
      "--- Writing batch 206 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 206 successfully processed and written to 3 tables.\n",
      "--- Writing batch 207 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 207 successfully processed and written to 3 tables.\n",
      "--- Writing batch 208 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 208 successfully processed and written to 3 tables.\n",
      "--- Writing batch 209 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 209 successfully processed and written to 3 tables.\n",
      "--- Writing batch 210 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 210 successfully processed and written to 3 tables.\n",
      "--- Writing batch 211 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 211 successfully processed and written to 3 tables.\n",
      "--- Writing batch 212 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 212 successfully processed and written to 3 tables.\n",
      "--- Writing batch 213 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 213 successfully processed and written to 3 tables.\n",
      "--- Writing batch 214 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 214 successfully processed and written to 3 tables.\n",
      "--- Writing batch 215 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 215 successfully processed and written to 3 tables.\n",
      "--- Writing batch 216 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 216 successfully processed and written to 3 tables.\n",
      "--- Writing batch 217 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 217 successfully processed and written to 3 tables.\n",
      "--- Writing batch 218 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 218 successfully processed and written to 3 tables.\n",
      "--- Writing batch 219 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 219 successfully processed and written to 3 tables.\n",
      "--- Writing batch 220 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 220 successfully processed and written to 3 tables.\n",
      "--- Writing batch 221 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 221 successfully processed and written to 3 tables.\n",
      "--- Writing batch 222 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 222 successfully processed and written to 3 tables.\n",
      "--- Writing batch 223 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 223 successfully processed and written to 3 tables.\n",
      "--- Writing batch 224 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 224 successfully processed and written to 3 tables.\n",
      "--- Writing batch 225 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 225 successfully processed and written to 3 tables.\n",
      "--- Writing batch 226 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 226 successfully processed and written to 3 tables.\n",
      "--- Writing batch 227 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 227 successfully processed and written to 3 tables.\n",
      "--- Writing batch 228 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 228 successfully processed and written to 3 tables.\n",
      "--- Writing batch 229 to SQL Server (Starting Split) ---\n",
      "  -> Wrote 1 rows to traffic_sensors_data.\n",
      "  -> Wrote 1 rows to traffic_weather_conditions.\n",
      "  -> Wrote 1 rows to traffic_energy_analysis.\n",
      "Batch 229 successfully processed and written to 3 tables.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "JAR_PATH = \"/opt/spark/jars/mssql-jdbc-13.2.1.jre11.jar\" \n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TrafficKafkaStreaming\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", JAR_PATH) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"traffic_topic\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "\n",
    "json_df = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", StringType()),\n",
    "    StructField(\"street_name\", StringType()),\n",
    "    StructField(\"vehicle_count\", IntegerType()),\n",
    "    StructField(\"vehicle_speed\", DoubleType()),\n",
    "    StructField(\"light_level\", StringType()),\n",
    "    StructField(\"weather\", StringType()),\n",
    "    StructField(\"traffic_light\", StringType()),\n",
    "    StructField(\"solar_energy_level\", DoubleType()),\n",
    "    StructField(\"lighting_demand\", StringType())\n",
    "])\n",
    "\n",
    "\n",
    "parsed_df = json_df.select(from_json(col(\"value\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "\n",
    "df_transformed = (parsed_df\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\")))\n",
    "    .withColumn(\"hour_of_day\", hour(col(\"timestamp\")))\n",
    "    .withColumn(\"day_of_week\", date_format(col(\"timestamp\"), \"EEEE\"))\n",
    "    .withColumn(\"Is_peak_hour\", when((col(\"hour_of_day\").between(7, 9)) | (col(\"hour_of_day\").between(16, 18)), 1).otherwise(0))\n",
    "    .withColumn(\"congestion_level\", when((col(\"vehicle_count\") >= 30) & (col(\"vehicle_speed\") <= 20), \"High\")\n",
    "                                    .when((col(\"vehicle_count\") >= 15) & (col(\"vehicle_speed\") <= 40), \"Medium\")\n",
    "                                    .otherwise(\"Low\"))\n",
    "    .withColumn(\"Is_congested\", when(col(\"congestion_level\") == \"High\", 1).otherwise(0))\n",
    "    .withColumn(\"lighting_demand_kW\", when(col(\"lighting_demand\") == \"low\", 0.5)\n",
    "                                      .when(col(\"lighting_demand\") == \"medium\", 2.0)\n",
    "                                      .when(col(\"lighting_demand\") == \"high\", 5.0))\n",
    "    .withColumn(\"lighting_consumption_kWh\", \n",
    "                when(col(\"lighting_demand_kW\") - col(\"solar_energy_level\") > 0,\n",
    "                     col(\"lighting_demand_kW\") - col(\"solar_energy_level\"))\n",
    "                .otherwise(0.0))\n",
    "   \n",
    "    .withColumn(\"energy_alert_flag\", \n",
    "        (col(\"lighting_consumption_kWh\") > 2.0).cast(IntegerType())\n",
    "    ) \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SQL_SERVER_HOST = \"host.docker.internal\" \n",
    "SQL_SERVER_PORT = \"1433\"\n",
    "DB_NAME = \"final-project\"\n",
    "DB_USER = \"sa\"\n",
    "DB_PASSWORD = \"maya\"\n",
    "\n",
    "\n",
    "JDBC_URL = f\"jdbc:sqlserver://{SQL_SERVER_HOST}:{SQL_SERVER_PORT};databaseName={DB_NAME};encrypt=true;trustServerCertificate=true\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def write_to_sql_server(df, epoch_id):\n",
    "    \"\"\"يقوم بتقسيم الدفعة إلى 3 جداول عادية (Flat Tables) وكتابتها.\"\"\"\n",
    "    print(f\"--- Writing batch {epoch_id} to SQL Server (Starting Split) ---\")\n",
    "\n",
    "  \n",
    "    jdbc_options = {\n",
    "        \"url\": JDBC_URL,\n",
    "        \"user\": DB_USER,\n",
    "        \"password\": DB_PASSWORD,\n",
    "        \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "       \n",
    "        sensors_df = df.select(\n",
    "            \"timestamp\", \"street_name\", \"vehicle_count\", \"vehicle_speed\",\n",
    "            \"hour_of_day\", \"day_of_week\", \"Is_peak_hour\", \"congestion_level\", \n",
    "            \"Is_congested\"\n",
    "        )\n",
    "        \n",
    "        sensors_df.write.format(\"jdbc\").options(\n",
    "            dbtable=\"traffic_sensors_data\", \n",
    "            **jdbc_options\n",
    "        ).mode(\"append\").save()\n",
    "        print(f\"  -> Wrote {sensors_df.count()} rows to traffic_sensors_data.\")\n",
    "\n",
    "\n",
    "        # B. جدول traffic_weather_conditions (الظروف البيئية)\n",
    "        weather_df = df.select(\n",
    "            \"timestamp\", \"street_name\", \"light_level\", \"weather\", \"traffic_light\"\n",
    "        )\n",
    "        \n",
    "        weather_df.write.format(\"jdbc\").options(\n",
    "            dbtable=\"traffic_weather_conditions\", \n",
    "            **jdbc_options\n",
    "        ).mode(\"append\").save()\n",
    "        print(f\"  -> Wrote {weather_df.count()} rows to traffic_weather_conditions.\")\n",
    "\n",
    "\n",
    "       \n",
    "        energy_df = df.select(\n",
    "            \"timestamp\", \n",
    "            \"street_name\",\n",
    "            \"solar_energy_level\",\n",
    "            \"lighting_demand\",\n",
    "            \"lighting_demand_kW\",\n",
    "            \"lighting_consumption_kWh\",\n",
    "            \"energy_alert_flag\"\n",
    "        )\n",
    "\n",
    "        energy_df.write.format(\"jdbc\").options(\n",
    "            dbtable=\"traffic_energy_analysis\", \n",
    "            **jdbc_options\n",
    "        ).mode(\"append\").save()\n",
    "        print(f\"  -> Wrote {energy_df.count()} rows to traffic_energy_analysis.\")\n",
    "\n",
    "\n",
    "        print(f\"Batch {epoch_id} successfully processed and written to 3 tables.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing batch {epoch_id} to SQL Server: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "query = df_transformed.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .option(\"checkpointLocation\", \"/home/jovyan/work/data_lake/checkpoints_sql_split\") \\\n",
    "    .foreachBatch(write_to_sql_server) \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61490f4e-b117-4317-8a5c-8a1379c12a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
